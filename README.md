# Comparing LLMs
This project contains code generated by various LLMs to the prompt (given in prompt.txt), using the evaluation-criteria, evaluation-criteria.md.

For claude code, installed using ```npm install -g @anthropic-ai/claude-code``` as documented [here](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview#install-and-authenticate)

Clauded got error:  "Credit balance too low · Add funds: https://console.anthropic.com/settings/billing"· Went there and spent 5 bucks, then prompted "retry the last prompt"

Nice prompt before chmode:

```
Bash command                                                                                             │
│                                                                                                          │
│   chmod +x dedup.sh                                                                                      │
│   Makes script 'dedup.sh' executable for running                                                         │
│                                                                                                          │
│ Do you want to proceed?                                                                                  │
│ ❯ 1. Yes                                                                                                 │
│   2. Yes, and don't ask again for chmod commands in                                                      │
│   /Users/johnlockwood/source/CodeSolid/llm-comparison/claude-code                                        │
│   3. No, and tell Claude what to do differently (esc)
```

```
Total cost:            $0.0886
Total duration (API):  26.6s
Total duration (wall): 30m 25.1s
Total code changes:    114 lines added, 0 lines removed
